{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vkjadon/introduction-to-deep-learning/blob/main/02pythonForDeepLearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Python for Deep Learning"
      ],
      "metadata": {
        "id": "YP3mN3XD7fRv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Welcome to the session on \"Python for Deep Learning\". NumPy is the most powerful Python library. We will be using the Google Colaboratory online resource for writting the Python Code. We will discuss various capabilities of NumPy in this session. Lets get started!"
      ],
      "metadata": {
        "id": "kIslAF3U7lJ7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Open the Google Coab using Google Search"
      ],
      "metadata": {
        "id": "iACSOdNa8jEj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NumPy Library"
      ],
      "metadata": {
        "id": "8n2waimFN5EX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"brown\">NumPy stands for “Numerical Python”.</font>\n",
        "\n",
        "It is a tool suited for array oriented computing efficiently.\n",
        "\n",
        "The “numpy array” uses less memory than python list and also the execution time is faster.\n",
        "\n",
        "The internal type of numpy array is “ndarray”.\n",
        "\n",
        "$A_{m,n} =\\begin{pmatrix}\n",
        "  a_{1,1} & a_{1,2} & \\cdots & a_{1,n} \\\\\n",
        "  a_{2,1} & a_{2,2} & \\cdots & a_{2,n} \\\\\n",
        "  \\vdots  & \\vdots  & \\ddots & \\vdots  \\\\\n",
        "  a_{m,1} & a_{m,2} & \\cdots & a_{m,n}\n",
        " \\end{pmatrix}$\n",
        "\n",
        "- The shape of this matrix is $m \\times n$\n",
        "\n",
        "- The $i, j$ are the indices used to indicate an element; where $i=1$ to $m$ and $j=1$ to $n$\n",
        "\n",
        "- We start by importing the NumPy library"
      ],
      "metadata": {
        "id": "95VlFCjYLb_C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Assigning Array"
      ],
      "metadata": {
        "id": "uEj8B8cY_hci"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BAnycimeqKwK"
      },
      "outputs": [],
      "source": [
        "# Import the NumPy library\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In deep learning, we often work with large datasets. NumPy arrays provide efficient storage and manipulation of numerical data.\n",
        "Let us create a two-dimensional NumPy array."
      ],
      "metadata": {
        "id": "1SC34KAkNCxO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrix of 4 Rows and 3 Columns :\n",
        "#In NumPy, this 2D matrix has Two axes\n",
        "#First axis length is 4 and Second axis length is 3 (4L,3L)\n",
        "\n",
        "matrixA = np.array([(1,2,3),(4,5,6),(7,2,3),(4,5,6)])\n",
        "print(matrixA)\n",
        "matrixB = np.array([[1,2,3],[4,5,6],[7,2,3],[4,5,6]])\n",
        "print(matrixB)\n",
        "print('Shape of Matrix', matrixA.shape)\n",
        "print('Dimension of Matrix', matrixA.ndim)\n",
        "print(\"Type of matrixA \", type(matrixA))"
      ],
      "metadata": {
        "id": "PQBmYm-1ND_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can reshape the matrixA using the reshape() function in NumPy. Reshaping allows you to change the shape or dimensions of an array while maintaining the same number of elements. So, we can reshape the 'matrixA' into another matrix of equal total numebr of elements. Otherwise, it will throw an error. We can specify one dimension by '-1' for the unknown shape. The Numpy will compute that on its own if exists.\n",
        "- We can use `.T` to transpose the matrix."
      ],
      "metadata": {
        "id": "J2fKUtb2QjvZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#matrixA.T\n",
        "#matrixA\n",
        "matrixA.reshape(6,-1)\n",
        "#matrixA.reshape(3,2,-1)\n",
        "#matrixA.reshape(3,4)\n",
        "#matrixA.shape\n",
        "#matrixA"
      ],
      "metadata": {
        "id": "mqDqHPOPPdqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Accessing Array Elements"
      ],
      "metadata": {
        "id": "aDUiTwOCR_a7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can access elements of the array using indexing, just like in regular Python lists."
      ],
      "metadata": {
        "id": "DYygciIr_MuN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Access elements of the array\n",
        "print(\"First matrix:\", matrixA)\n",
        "print(\"First element:\", matrixA[0])\n",
        "print(\"Last element:\", matrixA[-1])"
      ],
      "metadata": {
        "id": "0D86GGxGSAxh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Access elements of the array\n",
        "print(\"First element:\", matrixA[1,0])\n",
        "print(\"Last element:\", matrixA[2,-1])"
      ],
      "metadata": {
        "id": "cl0EFX2hSS6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Slicing (Colon Operator)\n"
      ],
      "metadata": {
        "id": "7J28UgNqx68t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Slicing is used to take desired elements of an array starting from one given index to another given index.\n",
        "\n",
        "`[start : end: step]` for 1D array.\n",
        "\n",
        "- **`start`** is inclusive and **`end`** is exclusive\n",
        "\n",
        "- If we don't pass `start` its considered 0\n",
        "\n",
        "- If we don't pass end its considered length of array in that dimension\n",
        "\n",
        "- If we don't pass `step` its considered 1"
      ],
      "metadata": {
        "id": "jYU8ut2j_abf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array([18, 2, 5, 3, 20])\n",
        "print(x[3:]) #All after index 3. x[3]=3, x[4]=20 # x[3] is Inclusive\n",
        "print(x[:4]) #All before index 4. x[0]=18, x[1]=2, x[2]=5, x[3]=3 # x[4] Exclusive"
      ],
      "metadata": {
        "id": "AA6UU-uzycph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use [`start` : `end`: `step` , `start` : `end`: `step` ] for 2D array."
      ],
      "metadata": {
        "id": "LmCosBZzVsTb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Slice of the array:\", matrixA[0:2])\n",
        "# print(\"Slice of the array:\", matrixA[2:2])\n",
        "print(\"Slice of the array:\", matrixA[1, 1:3])\n",
        "print(\"Slice of the array:\", matrixA[1, 1:-1])\n",
        "print(\"Slice of the array:\", matrixA[1, 1:8]) # No error"
      ],
      "metadata": {
        "id": "sfgMe6GmU-Ap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating a NumPy array"
      ],
      "metadata": {
        "id": "RJ82SZPcTW0x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## arange() function"
      ],
      "metadata": {
        "id": "sNJ77qzZ_vGw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`arange([start,] stop[, step], [, dtype=None])`\n",
        "\n",
        "**arange** returns evenly spaced values within a given interval starting from first optional parameter and within the `stop` value.\n",
        "If only one parameter is given, it is assumed as `stop` and the `start` is automatically set to 0.\n",
        "If the `step` is not given, it is set to `1` but if `step` is given, the `start` parameter cannot be optional, i.e. it has to be given as well.\n",
        "The `step` sets the spacing between two adjacent values of the output array."
      ],
      "metadata": {
        "id": "zQX3AiBnTy88"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dayTemperature=np.arange(6)\n",
        "#Gives 6 values starting from 0 and default interval of 1\n",
        "print(dayTemperature)"
      ],
      "metadata": {
        "id": "7b0CzpyIXuFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dayTemperature=np.arange(22,30,1)\n",
        "#First Value is 22 and it stops at 30, So 30 is not included\n",
        "print(dayTemperature)"
      ],
      "metadata": {
        "id": "E9wRQLfHXwSg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dayTemperature=np.arange(25)\n",
        "#First Value is 0 and it gives 25 output with default interval of 1\n",
        "print(dayTemperature)"
      ],
      "metadata": {
        "id": "cdPunCeKX4Zr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A=np.arange(12).reshape(4,3)\n",
        "A"
      ],
      "metadata": {
        "id": "7Wb75j4RYFN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##linspace() Function\n"
      ],
      "metadata": {
        "id": "8GqaqQQOTgpC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`linspace(start, stop, num=50, endpoint=True, retstep=False)`\n",
        "\n",
        "<font color='brown'>create NumPy array using linspacebar</font>\n",
        "\n",
        "Array of linearly spaced values defined by `num` including `start` and `stop`\n",
        "\n",
        "<font color='brown'>default value of num is 50</font>"
      ],
      "metadata": {
        "id": "u2aDzpbRT420"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dayTemperature=np.linspace(20,30,11)\n",
        "print(dayTemperature)"
      ],
      "metadata": {
        "id": "i0t0-0kvX757"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dayTemperature, spacing=np.linspace(20,30, 20, endpoint=True, retstep=True)\n",
        "print(dayTemperature, spacing)"
      ],
      "metadata": {
        "id": "EfOvvcc2X8zt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Using Random Functions"
      ],
      "metadata": {
        "id": "XqzZ5hJ4YNal"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use `np.random.rand` to create an array of the given shape and populate it with random samples from a uniform distribution over [0, 1)."
      ],
      "metadata": {
        "id": "bX-Ox8pwYLhp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A=np.random.rand(4,2)\n",
        "A"
      ],
      "metadata": {
        "id": "ZIFiEXxyYaow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use `np.random.randn` to generates an array of given shape, filled with random floats sampled from a univariate “normal” (Gaussian) distribution of mean 0 and variance 1."
      ],
      "metadata": {
        "id": "6pGUUxCEYe2b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A=np.random.randn(3,4)\n",
        "A"
      ],
      "metadata": {
        "id": "YVV3MNPWYjUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Color images are represented by 3D array corresponding to pixels in width, pixels in height for each of RGB channel. and reshape to a row or column matrix as below."
      ],
      "metadata": {
        "id": "FQRBRVdgeHJM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a=np.random.randn(64*64*3)\n",
        "image=a.reshape(64,64,3)\n",
        "print(image.shape[0])\n",
        "image.reshape(-1,1)"
      ],
      "metadata": {
        "id": "orCPufIfeK5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image.reshape(1,-1)"
      ],
      "metadata": {
        "id": "ogGvI1EIeNSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Matrix Multiplication"
      ],
      "metadata": {
        "id": "WVYSfZ-UcQw4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Element wise Multiplication"
      ],
      "metadata": {
        "id": "ZCAs9PofZvSm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- In NumPy the `*` operator indicates element-wise multiplication and is different from `np.dot`.\n",
        "\n",
        "- Dot Product is also known as inner product"
      ],
      "metadata": {
        "id": "j8bVik8ccly3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#a=np.random.randn(4,3)\n",
        "a=np.random.randn(3,2)\n",
        "b=np.random.randn(3,2)\n",
        "c=a*b\n",
        "print(c)"
      ],
      "metadata": {
        "id": "SwolFUM0cvh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- To perform element-wise multiplication, the dimension of both the arrays must be the same.\n",
        "- The otherwise the broadcating can be used."
      ],
      "metadata": {
        "id": "1us1irtLc5eG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dot Product or Inner Product"
      ],
      "metadata": {
        "id": "WxeoMg7eZ4hD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Consider random arrays of shape `a(4,3)` and `b(3,2)`.\n",
        "`np.dot(a, b)` has shape equal to number of rows of `a`, number of columns of `b`\n",
        "\n",
        "- To perform `dot product` on two muti-dimension arrays, the last dimension of the first array should be equal to last but one dimension of second array. So check `a.shape[-1]==b.shape[-2]`"
      ],
      "metadata": {
        "id": "YAqYZGzBdZNK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a=np.random.randn(256,15)\n",
        "b=np.random.randn(15,5)"
      ],
      "metadata": {
        "id": "_VleDq5QX1ZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(a.shape[-1], b.shape[-2])\n",
        "a.shape[-1] == b.shape[-2]"
      ],
      "metadata": {
        "id": "1yhaqA8KdYy6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if(a.shape[1] == b.shape[0]):\n",
        "  c=np.dot(a,b)\n",
        "  c.shape\n",
        "  print(c)\n",
        "else:\n",
        "  print(\"The columns and rows condition not satisfied\")"
      ],
      "metadata": {
        "id": "Wlvu9y5NdkWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a=np.random.randn(3,3)\n",
        "b=np.random.randn(3,1)\n",
        "c=a*b\n",
        "print(c)"
      ],
      "metadata": {
        "id": "pkiDMNHVd0Bk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Mathematical Functions"
      ],
      "metadata": {
        "id": "IwCICjkV3UY8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$y=f(x)$\n",
        "\n",
        "- Linear Function\n",
        "$$f(x) = wx+b$$\n",
        "$$f(x) = max(0,x)$$\n",
        "- Quadratic Function\n",
        "$$f(x) = 4ax^2+b$$\n",
        "- Exponential Function\n",
        "$$f(x) = \\frac{1}{1+e^{-x}}$$\n",
        "\n",
        "$$f(x_i) = \\frac {e^{x_i}}{\\sum_{j=1}^C{e^{x_j}}}$$\n",
        "\n",
        "- Trignometric Function\n",
        "$$f(x) = tan^{-1}(x)$$\n",
        "- Logrithmic Function\n",
        "$$f(x) = log(x)$$"
      ],
      "metadata": {
        "id": "BjpVoAl73hPG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuLV9P_XqKwI"
      },
      "source": [
        "## Sigmoid Function"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implement `np.exp()` and `math.exp()` for the sigmoid function and compare.\n",
        "\n",
        "$$sigmoid(x) = \\frac{1}{1+e^{-x}}$$\n",
        "\n",
        "- It takes an input value x and outputs a value between 0 and 1, which can be interpreted as a probability.\n",
        "- The function has an S-shaped curve, mapping the input values to a smooth, non-linear range.\n",
        "- The sigmoid function is commonly used in the last layer of a binary classification task, where the output represents the probability of belonging to a certain class."
      ],
      "metadata": {
        "id": "BBROrlLZUCWX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math"
      ],
      "metadata": {
        "id": "qwAGX22FWus6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lfihcHJDqKwL"
      },
      "outputs": [],
      "source": [
        "def sigmoid(z):\n",
        "  return 1/(1+math.exp(-z))\n",
        "sigmoid(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qe4z1dCcqKwN"
      },
      "source": [
        "<span style=\"color:brown\"> **Cannot pass array as an arguement**</span>\n",
        "\n",
        "Give it a try to pass array to find sigmoid function of all the array elements."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N9_A3wu-qKwN"
      },
      "outputs": [],
      "source": [
        "a=np.array([1,2,3])\n",
        "sigmoid(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G2s5uwxHqKwO"
      },
      "outputs": [],
      "source": [
        "def sigmoid(z):\n",
        "  return 1/(1+np.exp(-z))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0-LU3tcrqKwO"
      },
      "outputs": [],
      "source": [
        "# Example\n",
        "x = np.array([-1, 0, 1])\n",
        "output = sigmoid(x)\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2YNFIGmBqKwP"
      },
      "outputs": [],
      "source": [
        "w = np.array([[0.1124579], [0.23106775]])\n",
        "b = -0.3\n",
        "X = np.array([[1., -1.1, -3.2],[1.2, 2., 0.1]])\n",
        "A=sigmoid(np.dot(w.T,X)+b)\n",
        "print(A)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Broadcasting Example"
      ],
      "metadata": {
        "id": "6vwyfts3umkX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a=np.arange(12).reshape(4,3)\n",
        "b=np.arange(10,22).reshape(4,3)\n",
        "c=a*b\n",
        "print(c)"
      ],
      "metadata": {
        "id": "EkKupAFEc7JF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a=np.random.randn(3,4)\n",
        "b=np.random.randn(4,1)\n",
        "c=a+b.T\n",
        "print(\"Shape of a+b.T \",c.shape)\n",
        "c=a.T+b\n",
        "print(\"Shape of a.T+b \",c.shape)"
      ],
      "metadata": {
        "id": "rNGaWE2Mdq99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a=np.random.randn(256,15)\n",
        "b=np.random.randn(15,5)\n",
        "c=np.dot(a,b)\n",
        "c.shape"
      ],
      "metadata": {
        "id": "lT0YGjV0dTUA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5K1pvF11qKwT"
      },
      "outputs": [],
      "source": [
        "percent=100*x/sum\n",
        "print(percent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L6MYRxA6qKwU"
      },
      "outputs": [],
      "source": [
        "x = np.array([18, 2, 5, 3, 20]).reshape(5,1)\n",
        "y = np.array([9, 14, 15, 3, -200]).reshape(5,1)\n",
        "z=100*(abs(y-x))/x\n",
        "print(z)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "if x is a vector, then a Python operation such as $s = x + 3$ or $s = \\frac{1}{x}$ will output s as a vector of the same size as x."
      ],
      "metadata": {
        "id": "oAoXmRLKd9au"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(a)\n",
        "b=a+3\n",
        "print(b)\n",
        "b=b*7\n",
        "print(b)"
      ],
      "metadata": {
        "id": "RcbQItkPeBFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Ploting a Sigmoid Function"
      ],
      "metadata": {
        "id": "er1NjgHNVMQT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "Kh2AC4i6VoXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- use `plt.plot()` to plot the z values against the sigmoid function values (y).\n",
        "- `plt.title()` adds a title to the plot\n",
        "- `plt.xlabel()` and `plt.ylabel()` label the x and y axes\n",
        "- `plt.grid(True)` enable the grid\n",
        "- Finally the plot is displayed `plt.show()`"
      ],
      "metadata": {
        "id": "b3p-WbsBWHcJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate z values\n",
        "z = np.linspace(-10, 10, 100)\n",
        "\n",
        "# Compute sigmoid function for each z value\n",
        "y = sigmoid(z)\n",
        "\n",
        "# Plot the sigmoid function\n",
        "plt.plot(z, y)\n",
        "plt.title('Sigmoid Function')\n",
        "plt.xlabel('z')\n",
        "plt.ylabel('sigmoid(z)')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "X_5r6hhXVLB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ReLU (Rectified Linear Unit)"
      ],
      "metadata": {
        "id": "HexmVWYov9Lj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- It takes an input value x and returns x if it is positive, and 0 otherwise.\n",
        "- The ReLU function introduces non-linearity to the network by mapping negative values to 0, while leaving positive values unchanged.\n",
        "- ReLU is a popular choice due to its simplicity and ability to mitigate the vanishing gradient problem."
      ],
      "metadata": {
        "id": "IqBimLOLxb43"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def relu(x):\n",
        "    return np.maximum(0, x)"
      ],
      "metadata": {
        "id": "-6gHoSFwwCt8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let us consider the three observations\n",
        "x = np.array([-1, 0, 1])\n",
        "output = relu(x)\n",
        "print(output)"
      ],
      "metadata": {
        "id": "-7SllUxzwESN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate z values\n",
        "z = np.linspace(-10, 10, 100)\n",
        "\n",
        "# Compute ReLU function for each z value\n",
        "y = relu(z)\n",
        "\n",
        "# Plot the ReLU function\n",
        "plt.plot(z, y)\n",
        "plt.title('ReLU Function')\n",
        "plt.xlabel('z')\n",
        "plt.ylabel('relu(z)')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DnyEeMYKXFoy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Softmax"
      ],
      "metadata": {
        "id": "vH7NEXRaJyUt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The softmax function is commonly used in multi-class classification tasks.\n",
        "- Given an input vector x, the softmax function computes the probabilities for each class by exponentiating and normalizing the values.\n",
        "- The softmax function is defined as follows:\n",
        "\n",
        "$$P(C_i) = \\frac {e^{z_i}}{\\sum_{j=1}^C{e^{z_j}}}$$\n",
        "\n",
        "- The output of the softmax function is a probability distribution, ensuring that the sum of the probabilities across all classes is equal to 1."
      ],
      "metadata": {
        "id": "IKfbbC9lJ15k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(x, dim):\n",
        "    x_exp=np.exp(x)\n",
        "    if(dim>1):\n",
        "      x_sum=np.sum(x_exp, axis=1).reshape(x.shape[0],1)\n",
        "    else:\n",
        "      x_sum=np.sum(x_exp)\n",
        "    #print(x_sum)\n",
        "    return x_exp/x_sum"
      ],
      "metadata": {
        "id": "TW7ePRcxPyzQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array([[9, 2, 5, 0, 0], [7, 5, 0, 0 ,0], [7, 5, 0, 0 ,0]]).T\n",
        "print(x.shape)\n",
        "print(x)\n",
        "s=softmax(x, 2)\n",
        "print(s)"
      ],
      "metadata": {
        "id": "CRDmW7uMP5NQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate x values\n",
        "x = np.linspace(-10, 10, 100)\n",
        "\n",
        "# Compute Softmax function for each x value\n",
        "y = softmax(x,1)\n",
        "\n",
        "print(np.sum(y))\n",
        "print(y)\n",
        "\n",
        "# Plot the Softmax function\n",
        "plt.plot(x, y)\n",
        "plt.title('Softmax Function')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('softmax(x)')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3gw3xmIFYEJD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## np.sum()"
      ],
      "metadata": {
        "id": "BJamm2tquf9H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a=np.array([[1,4, 5],[3,5,8]])\n",
        "b=np.sum(a,axis=1)  # 0 is column and 1 is row\n",
        "b"
      ],
      "metadata": {
        "id": "q313n7HWeTaq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n5zhvbpGqKwT"
      },
      "outputs": [],
      "source": [
        "x = np.array([[9, 2, 5, 3, 10], [7, 5, 10, 2 ,6], [17, 1, 10, 20 ,10]])\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zb3K0gTCqKwT"
      },
      "outputs": [],
      "source": [
        "sum=x.sum(axis=0)\n",
        "# equivalent to sum=np.sum(x,axis=0)\n",
        "sum"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Mean Squared Error (MSE) Loss Function"
      ],
      "metadata": {
        "id": "dgRp_OM4wcsW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mean Squared Error (MSE) Loss Function:\n",
        "- The Mean Squared Error (MSE) loss function is widely used for regression problems.\n",
        "- It calculates the average squared difference between the predicted values and the true values.\n",
        "- For a set of m predictions $y_{pred}$ and corresponding true values $y_{true}$, the MSE loss is computed as:\n",
        "\n",
        "$$L_{mse}(\\hat{y},y) = \\sum_{i=0}^m( \\hat{y}^{(i)}-y^{(i)})^2$$\n",
        "\n",
        "- The MSE loss penalizes larger errors more than smaller errors due to the squaring operation.\n",
        "- Minimizing the MSE loss encourages the model to produce predictions that are closer to the true values."
      ],
      "metadata": {
        "id": "ZYYxFj9dwyFN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mse_loss(y, yhat):\n",
        "  loss = np.dot(abs(y-yhat).T, abs(y-yhat))/y.shape[0]\n",
        "  #Note that dor product gives you onle scalar.\n",
        "  # We have used y.shape[0] to calculate mean\n",
        "  #loss=np.mean((y - yhat) ** 2)\n",
        "  return loss"
      ],
      "metadata": {
        "id": "rl3Elj-HwfnI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Consider an example for three predictions\n",
        "y_true = np.array([1, 2, 3, 4])\n",
        "y_pred = np.array([1.5, 2.3, 3.2, 3.9])\n",
        "#Try the below statement to show the broadcasting\n",
        "#y_pred = np.array([1.5])\n",
        "#Note that the program will throw an error if the shape of both\n",
        "#y is not same except when either y_pred or y_true is one to facilitate the broadcating\n",
        "loss = mse_loss(y_true, y_pred)\n",
        "print(loss)"
      ],
      "metadata": {
        "id": "A7Q4A0d3w4kr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mse_loss(y_true, y_pred):\n",
        "    return np.mean((y_true - y_pred) ** 2)\n",
        "\n",
        "# Generate y_true values\n",
        "y_true = np.array([2,3,4,6])\n",
        "\n",
        "# Generate a range of y_pred values\n",
        "y_pred = np.linspace(-2, 6, 8)\n",
        "\n",
        "# Compute MSE loss for each y_pred value\n",
        "loss = [mse_loss(y_true, y) for y in y_pred]\n",
        "\n",
        "#Broadcast the y_pred in the mse_loss function to all the elements of y_true.\n",
        "#You can change the number of elements in the y_true from 1 to 10 (say)\n",
        "\n",
        "# Plot the MSE loss curve\n",
        "plt.plot(y_pred, loss)\n",
        "plt.title('Mean Squared Error (MSE) Loss')\n",
        "plt.xlabel('Predicted Values (y_pred)')\n",
        "plt.ylabel('Loss')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qXWC71z6eQ5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- [...]: This is a list comprehension, which is a concise way to create a new list by iterating over a sequence (in this case, the y_pred values) and performing a specific operation for each element.\n",
        "\n",
        "- The list comprehension loss = [mse_loss(y_true, y) for y in y_pred] iterates over each y value in y_pred, computes the Mean Square Error loss using mse_loss(y_true, y), and stores the results in the loss list."
      ],
      "metadata": {
        "id": "BYuwDOP0rq2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Binary Cross-Entropy Loss Function"
      ],
      "metadata": {
        "id": "Qm2aiHpS075o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The Binary Cross-Entropy loss function is commonly used for binary classification problems.\n",
        "- It measures the dissimilarity between the predicted probabilities and the true binary labels.\n",
        "- For a set of m predictions y_pred and corresponding true labels y_true, the Binary Cross-Entropy loss is computed as:\n",
        "\n",
        "\n",
        "$$L_{BCE} = -\\frac{1}{m} \\sum_{i=0}^m(ylog(\\hat{y}) + (1 - y)log(1 - \\hat{y}))$$\n",
        "\n",
        "- The BCE loss penalizes models that have large differences between the predicted probabilities and the true labels.\n",
        "- Minimizing the BCE loss encourages the model to assign higher probabilities to the correct class."
      ],
      "metadata": {
        "id": "t81E3Hmv05Fd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def binary_cross_entropy(y_true, y_pred):\n",
        "    return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n"
      ],
      "metadata": {
        "id": "JHHWWj8tJA3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = np.array([0, 1, 1])\n",
        "y_pred = np.array([0.3, 0.9, 0.7])\n",
        "loss = binary_cross_entropy(y_true, y_pred)\n",
        "print(loss)"
      ],
      "metadata": {
        "id": "IWIY3R62JSdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate y_true and y_pred values\n",
        "y_true = np.array([1, 0, 1, 0, 1])\n",
        "y_pred = np.linspace(0.01, 0.99, 100)\n",
        "\n",
        "# Compute Cross-Entropy loss for each y_true and y_pred pair\n",
        "loss = [binary_cross_entropy(y_true, y) for y in y_pred]\n",
        "\n",
        "# Plot the Cross-Entropy loss\n",
        "plt.plot(y_pred, loss)\n",
        "plt.title('Cross-Entropy Loss')\n",
        "plt.xlabel('Predicted Probability (y_pred)')\n",
        "plt.ylabel('Loss')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HNl0oSq0siJq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Categorical Cross-Entropy Loss Function"
      ],
      "metadata": {
        "id": "UPy9DUA33E0C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The Categorical Cross-Entropy loss function is commonly used for multi-class classification problems.\n",
        "- It measures the dissimilarity between the predicted class probabilities and the true class labels.\n",
        "- For a set of m predictions y_pred and corresponding true labels y_true, the Categorical Cross-Entropy loss is computed as:\n",
        "\n",
        "$$L_{CCE} = -\\frac{1}{m} \\sum (y) log(\\hat{y})$$\n",
        "\n",
        "- The CCE loss penalizes models that have low probabilities for the correct class.\n",
        "- Minimizing the CCE loss encourages the model to assign higher probabilities to the correct classes."
      ],
      "metadata": {
        "id": "IdwKYqBQ3CRU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Normalization"
      ],
      "metadata": {
        "id": "WKbuGqgJuMmE"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2_PXHnNqKwQ"
      },
      "source": [
        "Row Normalization is done by dividing each element of row of a given vector x by its norm based on row.\n",
        "\n",
        "It is changing x to $ \\frac{x}{\\| x\\|} $.\n",
        "\n",
        "We get a column vector of norm if we take the square root of the sum of squares of each row elements. Then divide each row by its norm to normalize rows.\n",
        "\n",
        "\n",
        "$$\\| x\\| = \\text{np.linalg.norm(x, axis=1, keepdims=True)}$$\n",
        "\n",
        "With `keepdims=True` the result will broadcast correctly against the original x.\n",
        "\n",
        "`axis=1` means you are going to get the norm in a row-wise manner. If you need the norm in a column-wise way, you would need to set `axis=0`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VOg8k8ApqKwQ"
      },
      "outputs": [],
      "source": [
        "x = np.array([[0, 3, 4],\n",
        "              [1, 6, 4]])\n",
        "x_norm=np.linalg.norm(x, axis=1, keepdims=True)\n",
        "x=x/x_norm\n",
        "print(\"Norm \", x_norm, \"\\nnormalizeRows(x) = \", x)"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
    },
    "kernelspec": {
      "display_name": "Python 3.7.9 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "03numpyFunctions.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}